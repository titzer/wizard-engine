// Copyright 2021 Ben L. Titzer. All rights reserved.
// See LICENSE for details of Apache 2.0 license.

// A thin wrapper around the kernel mmap() and mprotect() operations.
component Mmap {
	def PROT_NONE = LinuxConst.PROT_NONE;
	def PROT_READ = LinuxConst.PROT_READ;
	def PROT_WRITE = LinuxConst.PROT_WRITE;
	def PROT_EXEC = LinuxConst.PROT_EXEC;

	def reserve(size: u64, prot: int) -> Mapping {
		var flags = LinuxConst.MAP_PRIVATE | LinuxConst.MAP_ANONYMOUS;
		var r = Linux.syscall(LinuxConst.SYS_mmap, (Pointer.NULL, size, prot, flags, 0, 0));
		if (r.0 == -1) return null;
		var start = Pointer.NULL + r.0, end = start + i64.view(size);
		var range = MemoryRange.new(start, end);
		var mapping = Mapping.new(range);
		RiGc.registerFinalizer(mapping, range.unmap);
		return mapping;
	}
	def protect(start: Pointer, size: u64, prot: int) -> bool {
		var r = Linux.syscall(LinuxConst.SYS_mprotect, (start, size, prot));
		return r.0 == 0;
	}
}

// The (root) handle for a memory region. Don't lose it!
// When the mapping is garbage collected, the memory range will be unmapped automatically,
// if the underlying range has not been manually unmapped.
class Mapping(range: MemoryRange) { }

class MemoryRange {
	def var start: Pointer;
	def var end: Pointer;

	new(start, end) { }

	def unmap() {
		if (start == Pointer.NULL) return; // already deallocated
		Linux.syscall(LinuxConst.SYS_munmap, (start, end - start));
		start = end = Pointer.NULL;
	}
	def size() -> u64 {
		return u64.view(end - start);
	}
	def contains(p: Pointer) -> bool {
		return p >= start && p < end;
	}
	def range(offset: int, length: int) -> Range<byte> {
		return CiRuntime.forgeRange(this.start + offset, length);
	}
}
