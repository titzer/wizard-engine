// Copyright 2023 Wizard Authors. All rights reserved.
// See LICENSE for details of Apache 2.0 license.

// Statically-allocated buffer for pre-generated code (in compiled binary).
def PAGE_SIZE = 4096u;
def PAGE_SIZE_i: int = 4096;
def GLOBAL_BUFFER_MARKER = 0x7ACEBEEF778899AA;
def PREGEN_CODE_MARKER = 0x7FAACCEE;
def GLOBAL_BUFFER_HEADER_SIZE = 64;
def INL_SIZE = 60 * 1024;
def OOL_SIZE = 4 * 1024;
def TOTAL_SIZE = INL_SIZE + OOL_SIZE;
def global_buffer = allocGlobalBufferWithMarker(TOTAL_SIZE + PAGE_SIZE_i);
def allocGlobalBufferWithMarker(size: int) -> Array<byte> {
	var result = Array<byte>.new(size);
	var w = DataWriter.new().reset(result, 0, result.length);
	w.put_b64(GLOBAL_BUFFER_MARKER);
	return result;
}

// Interface to pre-generated code stubs.
def I: X86_64Interpreter;
component X86_64PreGenStubs {
	private var spcV3Entry: (WasmFunction, Pointer, Pointer) -> Throwable;
	// XXX: the RiUserCode objects must be pre-allocated.
	private def ic = X86_64InterpreterCode.new(Pointer.NULL, Pointer.NULL);
	private def spcLazyCompileStub = X86_64SpcCompileStub.new("lazy", Pointer.NULL, Pointer.NULL);
	private def spcTierUpCompileStub = X86_64SpcCompileStub.new("tierup", Pointer.NULL, Pointer.NULL);
	private def spcTrapsStub = X86_64SpcTrapsStub.new(Pointer.NULL, Pointer.NULL);
	private var rdtsc_func: () -> u64;

	def getInterpreterCode() -> X86_64InterpreterCode {
		return (gen(), I.interpreterCode).last;
	}
	def getIntV3Entry() -> (WasmFunction, Pointer) -> Throwable {
		return (gen(), I.interpreterCode.intV3Entry).last;
	}
	def getSpcV3Entry() -> (WasmFunction, Pointer, Pointer) -> Throwable {
		return (gen(), spcV3Entry).last;
	}
	def getSpcLazyCompileStub() -> X86_64SpcCompileStub {
		return (gen(), spcLazyCompileStub).last;
	}
	def getSpcTierUpCompileStub() -> X86_64SpcCompileStub {
		return (gen(), spcTierUpCompileStub).last;
	}
	def getSpcTrapsStub() -> X86_64SpcTrapsStub {
		return (gen(), spcTrapsStub).last;
	}
	def getSpcIntEntry() -> Pointer {
		gen();
		return I.interpreterCode.start + I.interpreterCode.intSpcEntryOffset;
	}
	def getRdtscFunc() -> () -> u64 {
		return (gen(), rdtsc_func).last;
	}

	def gen() {
		if (I.interpreterCode != null) return;
		// Deseralize or generate the pregen stubs
		I.interpreterCode = Metrics.pregen_time_us.run(deserializeOrGenerateCode, ());
		Metrics.pregen_bytes.val += u64.!(I.interpreterCode.end - I.interpreterCode.start);

		if (Debug.pregen) Trace.OUT.put1("Created pregen stubs in %d \xCE\xBCs.\n", Metrics.pregen_time_us.val).outln();
	}
	def genAndWriteIntoExecutable(executable: string) -> bool {
		// generate the code and write it into
		gen();
		// try to find {global_buffer} in {data}
		var d = DataReader.new(executable);
		// the global buffer contents will be at the same page alignment in the executable
		var page_offset = int.!((Pointer.atContents(global_buffer) - Pointer.NULL) & (PAGE_SIZE - 1));
		var found = -1;
		for (pos = page_offset; pos < d.limit; pos += PAGE_SIZE_i) {
			var val = d.at(pos).read_u64();
			if (val == GLOBAL_BUFFER_MARKER) { found = pos; break; }
		}
		if (found < 0) return false;
		if (Debug.pregen) {
			Trace.OUT.put2("Pregen buffer in executable @+%d (0x%x)", found, found).outln();
		}
		// Write the executable code and the offsets of {InterpreterCode} into the executable.
		var w = DataWriter.new().reset(executable, found, found);
		w.puta(global_buffer);		// write machine code
		w.at(found);			// back up to write offsets
		// Write the pregen code offsets to serialized memory (e.g. a file with global buffer).
		var out = w.put_b32;
		out(PREGEN_CODE_MARKER);
		out(ic.fastDispatchTableOffset);
		out(ic.probedDispatchTableOffset);
		out(ic.codeStart);
		out(ic.intV3EntryOffset);
		out(ic.intSpcEntryOffset);
		out(ic.intIntEntryOffset);
		out(ic.deoptReentryOffset);
		out(ic.oobMemoryHandlerOffset);
		out(ic.divZeroHandlerOffset);
		out(ic.stackOverflowHandlerOffset);
		out(ic.spcV3EntryOffset);
		out(ic.spcLazyCompileOffset);
		out(ic.spcTierUpCompileOffset);
		out(ic.spcTrapsStubOffset);
		out(ic.spcTrapsStubEnd);
		out(ic.rdtscOffset);
		out(ic.codeEnd);
		return true;
	}
	def deserializeOrGenerateCode() -> X86_64InterpreterCode {
		def d = DataReader.new(global_buffer);

		var start = Pointer.atContents(global_buffer);
		var range = MemoryRange.new(start, start + global_buffer.length);

		Debug.beforePregen();
		ic.start = range.start;

		// Try deserializing the pregen code offsets directly from the global buffer.
		var marker = d.read_u32();
		if (Debug.pregen) {
			Trace.OUT.put2("Pregen buffer marker = 0x%x (0x%x indicates generated)",
				marker, PREGEN_CODE_MARKER).outln();
		}
		if (marker == PREGEN_CODE_MARKER) {
			if (Debug.pregen) {
				Trace.OUT.put2("Pregen stubs exist in [0x%x ... 0x%x]",
					(range.start - Pointer.NULL),
					(range.end - Pointer.NULL));
				Trace.OUT.outln();
			}
			ic.fastDispatchTableOffset	= int.view(d.read_u32());
			ic.probedDispatchTableOffset	= int.view(d.read_u32());
			ic.codeStart			= int.view(d.read_u32());
			ic.intV3EntryOffset		= int.view(d.read_u32());
			ic.intSpcEntryOffset		= int.view(d.read_u32());
			ic.intIntEntryOffset		= int.view(d.read_u32());
			ic.oobMemoryHandlerOffset	= int.view(d.read_u32());
			ic.oobMemoryHandlerOffset	= int.view(d.read_u32());
			ic.divZeroHandlerOffset		= int.view(d.read_u32());
			ic.stackOverflowHandlerOffset	= int.view(d.read_u32());
			ic.spcV3EntryOffset		= int.view(d.read_u32());
			ic.spcLazyCompileOffset		= int.view(d.read_u32());
			ic.spcTierUpCompileOffset	= int.view(d.read_u32());
			ic.spcTrapsStubOffset		= int.view(d.read_u32());
			ic.spcTrapsStubEnd		= int.view(d.read_u32());
			ic.rdtscOffset			= int.view(d.read_u32());
			ic.codeEnd			= int.view(d.read_u32());
		} else {
			//         global buffer v   [0 ...                                         TOTAL_SIZE  ]
			//      |xxxxxxxxxxxxxxxx|h|l|marker|global_header|...|dispatch|...|inline_code|ool_code|___
			//      ^----elem0_offset----^
			// page ^                                       1KiB  ^       page ^      page ^
			var mask = 4095L;
			var elem0_offset = (start - Pointer.NULL) & mask;
			var alloc_offset = elem0_offset + 8 + GLOBAL_BUFFER_HEADER_SIZE;
			var aligned_offset = (alloc_offset + mask) & ~mask;
			var skip = int.!(aligned_offset - elem0_offset);

			if (Debug.pregen) {
				Trace.OUT.put3("Generating pregen stubs into [0x%x ... 0x%x], skipping %d bytes",
					(range.start - Pointer.NULL),
					(range.end - Pointer.NULL),
					skip);
				Trace.OUT.outln();
			}

			var w = DataWriter.new().reset(global_buffer, skip, skip);
			// Gen interpreter
			X86_64InterpreterGen.new(ic, w).gen(range);
			// Gen SPC entry
			ic.spcV3EntryOffset = w.atEnd().pos;
			X86_64Spc.genEntryStub(w);
			// Gen SPC lazy compile
			ic.spcLazyCompileOffset = w.atEnd().pos;
			X86_64Spc.genLazyCompileStub(w);
			// Gen SPC tierup compile
			ic.spcTierUpCompileOffset = w.atEnd().pos;
			X86_64Spc.genTierUpCompileStub(w, ic);
			// Gen SPC traps stub
			ic.spcTrapsStubOffset = w.atEnd().pos;
			X86_64Spc.genTrapsStub(w, spcTrapsStub);
			ic.spcTrapsStubEnd = w.atEnd().pos;
			// Gen rdtsc function
			ic.rdtscOffset = w.atEnd().pos;
			genRdtsc(w);
			ic.codeEnd = w.atEnd().pos;
		}
		// Finish the interpreter code.
		ic.end = range.start + ic.codeEnd;
		ic.setV3Entry();
		I.interpreterCode = ic;
		I.dispatchTable = ic.start +
			if(Instrumentation.probes.elem != null,
				ic.probedDispatchTableOffset,
				ic.fastDispatchTableOffset);

		// Write-protect the executable code for security and debugging
		Mmap.protect(range.start + ic.codeStart, u64.!(ic.codeEnd - ic.codeStart), Mmap.PROT_READ | Mmap.PROT_EXEC);

		// Register user code objects with the Virgil runtime.
		RiRuntime.registerUserCode(ic);

		// SPC entry point
		spcV3Entry = CiRuntime.forgeClosure<void,
			(WasmFunction, Pointer, Pointer), Throwable>(
				range.start + ic.spcV3EntryOffset, ());

		// SPC lazy compile
		spcLazyCompileStub.start = range.start + ic.spcLazyCompileOffset;
		spcLazyCompileStub.end = range.start + ic.spcTierUpCompileOffset;
		RiRuntime.registerUserCode(spcLazyCompileStub);

		// SPC tierup compile
		spcTierUpCompileStub.start = range.start + ic.spcTierUpCompileOffset;
		spcTierUpCompileStub.end = range.start + ic.spcTrapsStubOffset;
		RiRuntime.registerUserCode(spcTierUpCompileStub);

		// SPC traps stub
		spcTrapsStub.start = range.start + ic.spcTrapsStubOffset;
		spcTrapsStub.end = range.start + ic.spcTrapsStubEnd;
		RiRuntime.registerUserCode(spcTrapsStub);

		// RDTSC function
		var rdtscCode = range.start + ic.rdtscOffset;
		rdtsc_func = CiRuntime.forgeClosure<void, void, u64>(rdtscCode, ());

		// Trace results to help in debugging
		if (Debug.pregen || Debug.interpreter || Trace.compiler || Debug.compiler) {
			var s = range.start - Pointer.NULL;
			Trace.OUT
				.puts("Pregen interpreter and compiler stub addresses:\n")
				.put1("\tcode start:                0x%x\n", s + ic.codeStart)
				.put1("\tv3->int entry:      break *0x%x\n", s + ic.intV3EntryOffset)
				.put1("\tspc->int entry:     break *0x%x\n", s + ic.intSpcEntryOffset)
				.put1("\tint->int entry:     break *0x%x\n", s + ic.intIntEntryOffset)
				.put1("\tfast dispatch:             0x%x\n", s + ic.fastDispatchTableOffset)
				.put1("\tprobed dispatch:           0x%x\n", s + ic.probedDispatchTableOffset)
				.put1("\toob memory:         break *0x%x\n", s + ic.oobMemoryHandlerOffset)
				.put1("\tdivide by zero:     break *0x%x\n", s + ic.divZeroHandlerOffset)
				.put1("\tstack overflow:     break *0x%x\n", s + ic.stackOverflowHandlerOffset)
				.put1("\tv3->entry:          break *0x%x\n", s + ic.spcV3EntryOffset)
				.put1("\tspc lazy compile:   break *0x%x\n", s + ic.spcLazyCompileOffset)
				.put1("\tspc tierup compile: break *0x%x\n", s + ic.spcTierUpCompileOffset)
				.put2("\tspc traps stubs:           0x%x - 0x%x\n",
					s + ic.spcTrapsStubOffset, s + ic.spcTrapsStubEnd)
				.put1("\trdtsc:              break *0x%x\n", s + ic.rdtscOffset)
				.put1("\tcode end:                  0x%x\n", s + ic.codeEnd)
				.outln();
		}
		Debug.afterPregen();
		return ic;
	}
	def genRdtsc(w: DataWriter) {
		def asm = X86_64Assemblers.create64(w);
		asm.rdtsc();
		asm.q.shl_r_i(X86_64Regs.RDX, 32);
		asm.q.or_r_r(X86_64Regs.RAX, X86_64Regs.RDX); // XXX: use V3 return register symbolic constant
		asm.ret();
	}
}
