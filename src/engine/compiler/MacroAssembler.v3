// Copyright 2022 Ben L. Titzer. All rights reserved.
// See LICENSE for details of Apache 2.0 license.

type MasmAddr(base: Reg, offset: int) #unboxed {
	def plus(delta: int) -> MasmAddr { return MasmAddr(base, offset + delta); }
}
class MasmLabel(create_pos: int) {
	var offset: int;
}
// Abstract codegen interface. Used by all execution tiers (interpreter, single-pass compiler, optimizing compiler)
// as a portable assembler.
//
// Guide to suffixes (register classes):
//  i = register, 32-bit integer
//  l = register, 64-bit integer or ref
//  f = register, 32-bit float
//  d = register, 64-bit float
//  q = register, 128-bit vector
//  m = memory
//  s = slot in the value stack
class MacroAssembler(valuerep: Tagging, regConfig: RegConfig) {
	var unimplemented: void -> void;	// function to call for unimplemented bytecodes
	var trap_labels: Array<MasmLabel>;	// maps TrapReason to a label
	var source_locs: Vector<(int, int)>;	// list of (offset, source_loc) pairs
	var source_loc: int = -1;		// current source location, if any
	var newTrapLabel: TrapReason -> MasmLabel;
	var embeddedRefOffsets: Vector<int>;
	private var offsets: V3Offsets;

	new() {
		unimplemented = fatalUnimplemented;
		newTrapLabel = makeSharedTrapLabel;
	}

	def getOffsets() -> V3Offsets {
		if (offsets == null) offsets = V3Offsets.new();
		return offsets;
	}
	def curCodeBytes() -> u64 {
		return 0;
	}
	def curDataBytes() -> u64 {
		return 0;
	}
	def printCodeBytes(sb: StringBuilder, from: u64, to: u64) {
	}

	// Label operations
	def newLabel(create_pos: int) -> MasmLabel {
		return MasmLabel.new(create_pos);
	}
	def bindLabel(l: MasmLabel) {
	}
	def bindLabelTo(label: MasmLabel, offset: int) {
	}
	def makeSharedTrapLabel(reason: TrapReason) -> MasmLabel {
		if (trap_labels == null) trap_labels = Array.new(TrapReason.count);
		var l = trap_labels[reason.tag];
		if (l == null) l = trap_labels[reason.tag] = newLabel(-10 - reason.tag);
		return l;
	}
	def getTrapLabel(reason: TrapReason) -> MasmLabel {
		if (trap_labels == null) return null;
		return trap_labels[reason.tag];
	}
	// Abstract stack operations
	def slotAddr(slot: u32) -> MasmAddr {
		return MasmAddr(regConfig.vfp, int.view(slot) * valuerep.slot_size + valuerep.tag_size);
	}
	def tagAddr(slot: u32) -> MasmAddr {
		return MasmAddr(regConfig.vfp, int.view(slot) * valuerep.slot_size);
	}

	def getScratchReg(kind: ValueKind) -> Reg {
		return regConfig.scratch; // TODO: get kind-specific scratch register
	}
	def getV3ParamReg(kind: ValueKind, index: int) -> Reg;
	def getV3ReturnReg(kind: ValueKind, index: int) -> Reg;

	// Source locations
	def recordSourceLoc(offset: int) {
		if (source_loc < 0) return;
		if (source_locs == null) source_locs = Vector.new();
		source_locs.put(offset, source_loc);
	}
	def at(src: int) -> this {
		source_loc = src;
	}

	def recordRetSourceLoc();

	def emit_intentional_crash() {
	}

	// XXX: remove emit_ prefix?
	def emit_mov_r_s(kind: ValueKind, reg: Reg, slot: u32) { // utility method
		emit_mov_r_m(kind, reg, slotAddr(slot));
	}

	def emit_mov_s_r(kind: ValueKind, slot: u32, reg: Reg) { // utility method
		emit_mov_m_r(kind, slotAddr(slot), reg);
	}
	def emit_mov_s_k(kind: ValueKind, slot: u32, val: int) {
		match (kind) {
			I32 => emit_mov_s_i(slot, val);
			I64 => emit_mov_s_l(slot, val);
			REF => emit_mov_s_l(slot, val); // TODO: ref size, assert 0?
			F32 => emit_mov_s_f(slot, u32.view(val));
			F64 => emit_mov_s_d(slot, u64.view(long.view(val))); // TODO: zero extend?
			V128 => emit_mov_s_q(slot, u64.view(long.view(val)), if(val < 0, u64.max, 0)); // TODO: zero extend?
		}
	}
	def emit_mov_s_i(slot: u32, val: int) { // utility method
		emit_mov_m_i(slotAddr(slot), val);
	}
	def emit_mov_s_l(slot: u32, val: long) { // utility method
		emit_mov_m_l(slotAddr(slot), val);
	}
	def emit_mov_s_f(slot: u32, bits: u32) { // utility method
		emit_mov_m_f(slotAddr(slot), bits);
	}
	def emit_mov_s_d(slot: u32, bits: u64) { // utility method
		emit_mov_m_d(slotAddr(slot), bits);
	}
	def emit_mov_s_q(slot: u32, low: u64, high: u64) {
		emit_mov_m_q(slotAddr(slot), low, high);
	}
	def emit_mov_s_s(kind: ValueKind, dst_slot: u32, src_slot: u32) { // utility method
		emit_mov_m_m(kind, slotAddr(dst_slot), slotAddr(src_slot));
	}

	// Routines to emit code to access various V3 constructs.
	def emit_v3_Array_elem_r_rr(kind: ValueKind, dst: Reg, array: Reg, index: Reg) {
		// Generic code, may be overridden to be more efficient
		emit_shlw_r_i(index, logScaleOf(kind));
		emit_addw_r_r(array, index);
		emit_mov_r_m(kind, dst, MasmAddr(array, getOffsets().Array_contents));
	}
	def emit_v3_Array_elem_r_ri(kind: ValueKind, dst: Reg, array: Reg, index: int) {
		emit_mov_r_m(kind, dst, MasmAddr(array, getOffsets().Array_contents + index * scaleOf(kind)));
	}
	def emit_v3_Array_length_r_r(dst: Reg, array: Reg) {
		emit_mov_r_m(ValueKind.I32, dst, MasmAddr(array, getOffsets().Array_length));
	}
	def emit_v3_Array_bounds_check_rr(array: Reg, index: Reg, oob_label: MasmLabel) {
		// Generic code, may be overridden to be more efficient
		var scratch = regConfig.scratch;
		emit_mov_r_m(ValueKind.I32, scratch, MasmAddr(array, getOffsets().Array_length));
		emit_binop_r_r(Opcode.I32_LE_U, scratch, index);
		emit_br_r(scratch, MasmBrCond.I32_NONZERO, oob_label);
	}
	def emit_v3_HeapArray_vals_r_r(dst: Reg, ptr: Reg) {
		emit_mov_r_m(ValueKind.REF, dst, MasmAddr(ptr, getOffsets().HeapArray_vals));
	}
	def emit_v3_Instance_dropped_elems_r_r(dst: Reg, ptr: Reg) {
		emit_mov_r_m(ValueKind.REF, dst, MasmAddr(ptr, getOffsets().Instance_dropped_elems));
	}
	def emit_v3_Instance_dropped_data_r_r(dst: Reg, ptr: Reg) {
		emit_mov_r_m(ValueKind.REF, dst, MasmAddr(ptr, getOffsets().Instance_dropped_data));
	}
	def emit_v3_Instance_tables_r_r(dst: Reg, ptr: Reg) {
		emit_mov_r_m(ValueKind.REF, dst, MasmAddr(ptr, getOffsets().Instance_tables));
	}
	def emit_v3_Instance_memories_r_r(dst: Reg, ptr: Reg) {
		emit_mov_r_m(ValueKind.REF, dst, MasmAddr(ptr, getOffsets().Instance_memories));
	}
	def emit_v3_Instance_heaptypes_r_r(dst: Reg, ptr: Reg) {
		emit_mov_r_m(ValueKind.REF, dst, MasmAddr(ptr, getOffsets().Instance_heaptypes));
	}
	def emit_v3_Instance_globals_r_r(dst: Reg, ptr: Reg) {
		emit_mov_r_m(ValueKind.REF, dst, MasmAddr(ptr, getOffsets().Instance_globals));
	}
	def emit_v3_Table_elems_r_r(dst: Reg, ptr: Reg) {
		emit_mov_r_m(ValueKind.REF, dst, MasmAddr(ptr, getOffsets().Table_elems));
	}
	def emit_v3_Table_ids_r_r(dst: Reg, ptr: Reg) {
		emit_mov_r_m(ValueKind.REF, dst, MasmAddr(ptr, getOffsets().Table_ids));
	}
	def emit_v3_Table_funcs_r_r(dst: Reg, ptr: Reg) {
		emit_mov_r_m(ValueKind.REF, dst, MasmAddr(ptr, getOffsets().Table_funcs));
	}
	def emit_v3_WasmFunction_instance_r_r(dst: Reg, ptr: Reg) {
		emit_mov_r_m(ValueKind.REF, dst, MasmAddr(ptr, getOffsets().WasmFunction_instance));
	}
	def emit_v3_WasmFunction_decl_r_r(dst: Reg, ptr: Reg) {
		emit_mov_r_m(ValueKind.REF, dst, MasmAddr(ptr, getOffsets().WasmFunction_decl));
	}
	def emit_v3_FuncDecl_target_code_r_r(dst: Reg, ptr: Reg) {
		emit_mov_r_m(ValueKind.REF, dst, MasmAddr(ptr, getOffsets().FuncDecl_target_code));
	}
	def emit_v3_Instance_functions_r_r(dst: Reg, ptr: Reg) {
		emit_mov_r_m(ValueKind.REF, dst, MasmAddr(ptr, getOffsets().Instance_functions));
	}
	def emit_v3_ContDecl_sig_r_r(dst: Reg, ptr: Reg) {
		emit_mov_r_m(ValueKind.REF, dst, MasmAddr(ptr, getOffsets().ContDecl_sig));
	}
	def emit_v3_SigDecl_params_r_r(dst: Reg, ptr: Reg) {
		emit_mov_r_m(ValueKind.REF, dst, MasmAddr(ptr, getOffsets().SigDecl_params));
	}
	def emit_v3_SigDecl_results_r_r(dst: Reg, ptr: Reg) {
		emit_mov_r_m(ValueKind.REF, dst, MasmAddr(ptr, getOffsets().SigDecl_results));
	}
	def emit_v3_Continuation_stack_r_r(dst: Reg, ptr: Reg) {
		emit_mov_r_m(ValueKind.REF, dst, MasmAddr(ptr, getOffsets().Continuation_stack));
	}
	
	// Must be overridden in architecture-specific subclass.
	def emit_v3_Memory_start_r_r(dst: Reg, memobj: Reg);
	def emit_v3_Memory_limit_r_r(dst: Reg, memobj: Reg);
	def emit_v3_X86_64Stack_vsp_r_r(dst: Reg, ptr: Reg);
	def emit_v3_X86_64Stack_rsp_r_r(dst: Reg, ptr: Reg);
	def emit_v3_set_X86_64Stack_vsp_r_r(stk: Reg, vsp: Reg);
	def emit_v3_set_X86_64Stack_rsp_r_r(stk: Reg, rsp: Reg);
	
	def emit_push_X86_64Stack_rsp_r_r(stk: Reg);
	def emit_pop_X86_64Stack_rsp_r_r(stk: Reg);

	def scaleOf(kind: ValueKind) -> int {
		match (kind) {
			I32, F32 => return 4;
			I64, F64 => return 8;
			REF => return 8; // override in subclasses if any 32-bit port
			V128 => return 16;
		}
	}
	def logScaleOf(kind: ValueKind) -> u6 {
		match (kind) {
			I32, F32 => return 2;
			I64, F64 => return 3;
			REF => return 3; // override in subclasses if any 32-bit port
			V128 => return 4;
		}
	}

	// Architecture-specific load and store routines for Wasm load/store.
	def emit_loadbsx_r_r_r_i(kind: ValueKind, dst: Reg, base: Reg, index: Reg, offset: u32);
	def emit_loadbzx_r_r_r_i(kind: ValueKind, dst: Reg, base: Reg, index: Reg, offset: u32);
	def emit_loadwsx_r_r_r_i(kind: ValueKind, dst: Reg, base: Reg, index: Reg, offset: u32);
	def emit_loadwzx_r_r_r_i(kind: ValueKind, dst: Reg, base: Reg, index: Reg, offset: u32);
	def emit_loaddsx_r_r_r_i(kind: ValueKind, dst: Reg, base: Reg, index: Reg, offset: u32);
	def emit_loaddzx_r_r_r_i(kind: ValueKind, dst: Reg, base: Reg, index: Reg, offset: u32);
	def emit_load_r_r_r_i(kind: ValueKind, dst: Reg, base: Reg, index: Reg, offset: u32);

	def emit_storeb_r_r_r_i(kind: ValueKind, val: Reg, base: Reg, index: Reg, offset: u32);
	def emit_storew_r_r_r_i(kind: ValueKind, val: Reg, base: Reg, index: Reg, offset: u32);
	def emit_store_r_r_r_i(kind: ValueKind, val: Reg, base: Reg, index: Reg, offset: u32);

	def emit_mov_r_r(kind: ValueKind, reg: Reg, reg2: Reg);
	def emit_mov_r_m(kind: ValueKind, reg: Reg, addr: MasmAddr);
	def emit_mov_r_k(kind: ValueKind, reg: Reg, val: int) {
		match (kind) {
			I32 => emit_mov_r_i(reg, val);
			I64 => emit_mov_r_l32(reg, val);
			REF => emit_mov_r_l32(reg, val); // TODO: ref size, assert 0?
			F32 => emit_mov_r_f32(reg, u32.view(val));
			F64 => emit_mov_r_d64(reg, u64.view(val));
			V128 => emit_mov_r_q(reg, u64.view(long.view(val)), if(val < 0, u64.max, 0)); // TODO: zero extend?
		}
	}
	def emit_mov_r_i(reg: Reg, val: int);
	def emit_mov_r_trap(reg: Reg, reason: TrapReason);
	def emit_mov_r_l32(reg: Reg, val: int);
	def emit_mov_r_l(reg: Reg, val: long);
	def emit_mov_r_f32(reg: Reg, val: u32);
	def emit_mov_r_d64(reg: Reg, val: u64);
	def emit_mov_r_q(reg: Reg, low: u64, high: u64);
	def emit_mov_r_Object(reg: Reg, obj: Object);
	def emit_mov_r_Function(reg: Reg, func: Function);
	def emit_mov_r_Instance(reg: Reg, instance: Instance);

	def emit_mov_m_r(kind: ValueKind, addr: MasmAddr, reg: Reg);
	def emit_mov_m_i(addr: MasmAddr, val: int);
	def emit_mov_m_l(addr: MasmAddr, val: long);
	def emit_mov_m_f(addr: MasmAddr, bits: u32);
	def emit_mov_m_d(addr: MasmAddr, bits: u64);
	def emit_mov_m_q(addr: MasmAddr, low: u64, high: u64);
	def emit_mov_m_m(kind: ValueKind, dst: MasmAddr, src: MasmAddr);

	// Word-oriented arithmetic for assembling some sequences.
	def emit_addw_r_i(r1: Reg, val: int);
	def emit_addw_r_r(r1: Reg, r2: Reg);
	def emit_subw_r_i(r1: Reg, val: int);
	def emit_subw_r_r(r1: Reg, r2: Reg);
	def emit_shlw_r_i(r1: Reg, imm: u6);
	def emit_shld_r_i(r1: Reg, imm: u5);
	def emit_shrw_r_i(r1: Reg, imm: u6);
	def emit_shrd_r_i(r1: Reg, imm: u5);
	def emit_sarw_r_i(r1: Reg, imm: u6);
	def emit_sard_r_i(r1: Reg, imm: u5);

	def emit_binop_r_r(op: Opcode, reg: Reg, reg2: Reg);
	def emit_binop_r_m(op: Opcode, reg: Reg, addr: MasmAddr);
	def emit_binop_r_i(op: Opcode, reg: Reg, val: int);

	def emit_pop_r(kind: ValueKind, reg: Reg);
	def emit_ret();
	def emit_nop();

	def emit_br(label: MasmLabel);
	def emit_br_r(reg: Reg, cond: MasmBrCond, label: MasmLabel);
	def emit_br_m(addr: MasmAddr, cond: MasmBrCond, label: MasmLabel);

	def emit_breq_r_i(reg: Reg, val: int, label: MasmLabel);
	def emit_breq_r_l(reg: Reg, val: int, label: MasmLabel);
	def emit_brne_r_i(reg: Reg, val: int, label: MasmLabel);

	def emit_br_table_r(reg: Reg, labels: Array<MasmLabel>);

	def emit_call_label(label: MasmLabel);
	def emit_call_r(reg: Reg);
	def emit_jump_r(reg: Reg);

	def emit_call_HostCallStub();
	def emit_jump_HostCallStub();

	def emit_call_runtime_callHost(func_arg: Reg);
	def emit_call_runtime_SUSPEND();
	def emit_call_runtime_SWITCH();
	def emit_call_runtime_RESUME_THROW();
	def emit_jump_to_trap_at(reason: TrapReason);
	def emit_call_runtime_op(op: Opcode);
	def emit_get_curstack(r: Reg);
	def emit_set_curstack(r: Reg);
	def emit_store_curstack_vsp(vsp: Reg);
	def emit_load_curstack_vsp(vsp: Reg);
	def emit_call_runtime_Probe_instr();
	def emit_call_runtime_getFrameAccessorMetaRef();
	def emit_increment_CountProbe(tmp: Reg, probe: CountProbe, increment: u64);
	def emit_call_OperandProbe_i_v_fire(probe: OperandProbe_i_v, value_reg: Reg);
	def emit_call_MemoryReadProbe_fire(probe: MemoryReadProbe);
	def emit_call_runtime_cast();
	def emit_call_runtime_checkFuncSigSubtyping();

	def emit_debugger_breakpoint();

	// stk.state_ = state;
	def emit_set_stack_state(stk: Reg, state: StackState);
	// This should be called after all stack value transfers, but before the
	// return address is pushed onto parent's {sp}.
	// Chains {cont} on {parent} by:
	// - setting the state of both {parent} and {cont}
	// - setting {cont.parent} and {cont.parent_rsp_ptr}
	// Destructive on {parent}.
	def emit_cont_mv(from_vsp: Reg, contStack: Reg, n_vals: Reg, tmp1: Reg, tmp2: Reg, xmm0: Reg);

	// Validates {cont} and:
	// - Move {cont.stack} to {cont}
	// - Set original {cont.stack} to {null}
	def emit_validate_and_consume_cont(cont: Reg) {
		var scratch = regConfig.scratch, offsets = getOffsets();
		emit_br_r(cont, MasmBrCond.REF_NULL, newTrapLabel(TrapReason.NULL_DEREF));
		emit_mov_r_m(ValueKind.REF, scratch, MasmAddr(cont, offsets.Continuation_stack));
		emit_br_r(scratch, MasmBrCond.REF_NULL, newTrapLabel(TrapReason.USED_CONTINUATION));
		emit_mov_m_l(MasmAddr(cont, offsets.Continuation_stack), 0);
		emit_mov_r_r(ValueKind.REF, cont, scratch);
	}
	// Called as the last step during resume. Switches {curStack} to the top of {cont}.
	def emit_chain_cont_to_parent(parent: Reg, contStack: Reg) {
		var scratch = regConfig.scratch, offsets = getOffsets();
		emit_set_stack_state(parent, StackState.CALL_CHILD); // XXX: not needed for {switch}
		emit_mov_r_r(ValueKind.REF, scratch, contStack);
		emit_set_stack_state(scratch, StackState.RUNNING);

		// cont.stack.cont_bottom.parent = parent;
		emit_mov_r_m(ValueKind.REF, scratch, MasmAddr(scratch, offsets.X86_64Stack_bottom));
		emit_mov_m_r(ValueKind.REF, MasmAddr(scratch, offsets.X86_64Stack_parent), parent);

		// *(cont.stack.cont_bottom.parent_rsp_ptr) = parent.rsp;
		emit_mov_r_m(ValueKind.REF, parent, MasmAddr(parent, offsets.X86_64Stack_rsp));
		emit_mov_r_m(ValueKind.REF, scratch, MasmAddr(scratch, offsets.X86_64Stack_parent_rsp_ptr));
		emit_mov_m_r(ValueKind.REF, MasmAddr(scratch, 0), parent);

		// contStack.cont_bottom = null;
		emit_mov_m_i(MasmAddr(contStack, offsets.X86_64Stack_bottom), 0);
	}
	def emit_switch_to_stack(r_stack: Reg) {
		var scratch = regConfig.scratch;
		emit_set_curstack(r_stack);
		emit_v3_X86_64Stack_rsp_r_r(regConfig.sp, r_stack);
		emit_pop_r(ValueKind.REF, scratch);
		emit_jump_r(scratch);
	}

	def fatalUnimplemented();

	def negate(cond: MasmBrCond) -> MasmBrCond {
		match (cond) {
			I1_ZERO 		=> return MasmBrCond.I1_ONE;
			I1_ONE			=> return MasmBrCond.I1_ZERO;
			I32_ZERO 		=> return MasmBrCond.I32_NONZERO;
			I32_NONZERO		=> return MasmBrCond.I32_ZERO;
			I64_ZERO		=> return MasmBrCond.I64_NONZERO;
			I64_NONZERO		=> return MasmBrCond.I64_ZERO;
			REF_NULL		=> return MasmBrCond.REF_NONNULL;
			REF_NONNULL		=> return MasmBrCond.REF_NULL;
			IS_WASM_FUNC		=> return MasmBrCond.IS_NOT_WASM_FUNC;
			IS_NOT_WASM_FUNC	=> return MasmBrCond.IS_WASM_FUNC;
		}
	}

	def addEmbeddedRefOffset(offset: int) {
		if (embeddedRefOffsets == null) embeddedRefOffsets = Vector.new();
		embeddedRefOffsets.put(offset);
	}
}
// Conditions for single-value branches
enum MasmBrCond		(zero: bool, 	i32: bool) {
	I1_ZERO		(true, 		true),
	I1_ONE		(false, 	true),
	I32_ZERO	(true, 		true),
	I32_NONZERO	(false, 	true),
	I64_ZERO	(true, 		false),
	I64_NONZERO	(false,		false),
	REF_NULL	(true,		false),
	REF_NONNULL	(false,		false),
	IS_WASM_FUNC	(true,		false),
	IS_NOT_WASM_FUNC(false,		false)
}
